---
title: "R Notebook"
output: html_notebook
---

Carga inicial del dataframe de tweets COVID-19
```{r}
library(mongolite)
library(ggplot2)
library(dplyr)
library(tidyr)
library(dplyr)
library(tm, exclude = "inspect")
library(stringr)
library(stringi)
library(arules)
library(tokenizers)


tweets_mongo_covid19 <- mongo(
  collection = "tweets_mongo_covid19", 
  db = "DMUBA"
)
```

```{r}
### ----- Tratamiento de Textos ------------
df_text = tweets_mongo_covid19$find(query = '{}',  fields = '{"user_id" : true, "text" : true, "_id": false}')
```

```{r}
# Se quitan caracteres no alfanuméricos (por cuestiones de errores en RStudio)
df_text$text <- gsub("[^[:alnum:][:blank:]?&/\\-]", "", df_text$text)
df_text$text <- gsub("U00..", "", df_text$text)
```

```{r}
# --- limpieza de textos
# Se quitan acentos
df_text$text = stri_trans_general(df_text$text, "Latin-ASCII")
# Se pasa a minusculas
df_text$text = tolower(df_text$text)
# Se quita puntuacion
df_text$text = removePunctuation(df_text$text)
# Se quitan números
df_text$text = removeNumbers(df_text$text)
# se quitan espacios extras
df_text$text =  stripWhitespace(df_text$text)
# se quitan espacios al principio y final de la cadena
df_text$text = str_trim(df_text$text)
# sin stop words
df_text$text = removeWords(df_text$text, stopwords("spanish"))
```

```{r}
# se separa el texto en términos
df_text$words = tokenizers::tokenize_words(df_text$text, simplify = T)
```

```{r}
# se pasa a formato pares: user-término
df_text = df_text %>% select("user_id", "words")  %>% unnest(words) %>%  distinct()
```

```{r}
# se agrega prefijo de tipo de ítem:
df_text$item = paste0("word=", df_text$words)
```

```{r}
# reglas
trans2 <- as(split(df_text$item, df_text$user_id), "transactions")
print(trans2)
rules = apriori(trans2, parameter=list(target="rule", support=0.15, confidence=0.2))
print(rules)
View(inspect(sort(rules, by="lift", decreasing = TRUE)[1:3]))
inspect(head(rules, 20))

```

