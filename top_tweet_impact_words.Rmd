---
title: "Retweet & Quotes vs Text Analisis"
output: html_notebook
---

Carga inicial del dataframe de tweets COVID-19
```{r}
library(mongolite)
library(ggplot2)
library(dplyr)
library(tidyr)
library(dplyr)
library(tm, exclude = "inspect")
library(stringr)
library(stringi)
library(arules)
library(tokenizers)

tweets_mongo_covid19 <- mongo(
  collection = "tweets_mongo_covid19", 
  db = "DMUBA"
)
```

Obtenemos nuestros tweets
```{r}
df_tweets = tweets_mongo_covid19$find(
  fields= 
  '{
      "retweet_status_id": 1,  
      "retweet_user_id": 1,
      "retweet_text": 1,
      "retweet_screen_name": 1,
      "retweet_verified": 1,
      "retweet_location": 1,
      "retweet_source": 1,
      "retweet_favorite_count": 1,
      "retweet_retweet_count": 1,
      "retweet_statuses_count": 1,
      "retweet_followers_count": 1,
      "retweet_friends_count": 1,
      
      "quoted_status_id": 1,  
      "quoted_user_id": 1,
      "quoted_text": 1,
      "quoted_screen_name": 1,
      "quoted_verified": 1,
      "quoted_location": 1,
      "quoted_source": 1,
      "quoted_favorite_count": 1,
      "quoted_retweet_count": 1,
      "quoted_statuses_count": 1,
      "quoted_followers_count": 1,
      "quoted_friends_count": 1
  }'
)
```

Extraemos los datos de aquellos que fueron retweets y los transformamos a un unico modelo
```{r}
retweeted_tweets_header <- c(
  'retweet_status_id',
  'retweet_user_id',
  'retweet_text',
  'retweet_screen_name',
  'retweet_verified',
  'retweet_location',
  'retweet_source',
  'retweet_favorite_count',
  'retweet_retweet_count',
  'retweet_statuses_count',
  'retweet_followers_count',
  'retweet_friends_count'
)

retweeted_tweets = df_tweets[,retweeted_tweets_header]

names(retweeted_tweets)[names(retweeted_tweets) == 'retweet_status_id'] <- 'status_id'
names(retweeted_tweets)[names(retweeted_tweets) == 'retweet_user_id'] <- 'user_id'
names(retweeted_tweets)[names(retweeted_tweets) == 'retweet_text'] <- 'text'
names(retweeted_tweets)[names(retweeted_tweets) == 'retweet_screen_name'] <- 'screen_name'
names(retweeted_tweets)[names(retweeted_tweets) == 'retweet_verified'] <- 'verified'
names(retweeted_tweets)[names(retweeted_tweets) == 'retweet_location'] <- 'location'
names(retweeted_tweets)[names(retweeted_tweets) == 'retweet_source'] <- 'source'
names(retweeted_tweets)[names(retweeted_tweets) == 'retweet_favorite_count'] <- 'favorite_count'
names(retweeted_tweets)[names(retweeted_tweets) == 'retweet_retweet_count'] <- 'retweet_count'
names(retweeted_tweets)[names(retweeted_tweets) == 'retweet_statuses_count'] <- 'statuses_count'
names(retweeted_tweets)[names(retweeted_tweets) == 'retweet_followers_count'] <- 'followers_count'
names(retweeted_tweets)[names(retweeted_tweets) == 'retweet_friends_count'] <- 'friends_count'

```

Extraemos los datos de aquellos que fueron Quotes y los transformamos a un unico modelo
```{r}
quoted_tweets_header <- c(
  'quoted_status_id',
  'quoted_user_id',
  'quoted_text',
  'quoted_screen_name',
  'quoted_verified',
  'quoted_location',
  'quoted_source',
  'quoted_favorite_count',
  'quoted_retweet_count',
  'quoted_statuses_count',
  'quoted_followers_count',
  'quoted_friends_count'
)

quoted_tweets = df_tweets[,quoted_tweets_header]

names(quoted_tweets)[names(quoted_tweets) == 'quoted_status_id'] <- 'status_id'
names(quoted_tweets)[names(quoted_tweets) == 'quoted_user_id'] <- 'user_id'
names(quoted_tweets)[names(quoted_tweets) == 'quoted_text'] <- 'text'
names(quoted_tweets)[names(quoted_tweets) == 'quoted_screen_name'] <- 'screen_name'
names(quoted_tweets)[names(quoted_tweets) == 'quoted_verified'] <- 'verified'
names(quoted_tweets)[names(quoted_tweets) == 'quoted_location'] <- 'location'
names(quoted_tweets)[names(quoted_tweets) == 'quoted_source'] <- 'source'
names(quoted_tweets)[names(quoted_tweets) == 'quoted_favorite_count'] <- 'favorite_count'
names(quoted_tweets)[names(quoted_tweets) == 'quoted_retweet_count'] <- 'retweet_count'
names(quoted_tweets)[names(quoted_tweets) == 'quoted_statuses_count'] <- 'statuses_count'
names(quoted_tweets)[names(quoted_tweets) == 'quoted_followers_count'] <- 'followers_count'
names(quoted_tweets)[names(quoted_tweets) == 'quoted_friends_count'] <- 'friends_count'

```

Combinamos y unificamos retweets y quotes
```{r}
combined_tweets = rbind(retweeted_tweets, quoted_tweets)
```

Ordenamos los tweets por retweet_count de forma decreciente
```{r}
top_tweets_by_retweet_count = combined_tweets

# Ordenamos por retweet_count de manera decreciente, hay mismos tw con distinto retweet_count
top_tweets_by_retweet_count = data.frame(
  top_tweets_by_retweet_count %>%
  group_by(status_id) %>%
  arrange(-retweet_count) %>%
  filter(row_number()==1)
)
```

Discretizamos nuestros valores
```{r}
# Se discretizan variables numericas (solo RT_count)

#top_tweets_by_retweet_count$cat_friends =discretize(top_tweets_by_retweet_count$friends_count, labels=c("pocos", "medio", "muchos"))
#top_tweets_by_retweet_count$cat_favorite =discretize(log10(top_tweets_by_retweet_count$favorite_count+1),method = "fixed", breaks = c(-Inf, 0.0001, 1.5, 2, Inf), labels=c("nada","pocos", "medio", "muchos"))
#top_tweets_by_retweet_count$cat_statuses =discretize(top_tweets_by_retweet_count$statuses_count, labels=c("pocos", "medio", "muchos"))
#top_tweets_by_retweet_count$cat_followers =discretize(top_tweets_by_retweet_count$followers_count, labels=c("pocos", "medio", "muchos"))
#top_tweets_by_retweet_count$cat_verified =  as.factor(ifelse(top_tweets_by_retweet_count$verified, "si", NA))

top_tweets_by_retweet_count$cat_rt = discretize(
  log10(top_tweets_by_retweet_count$retweet_count+1),
  method = "fixed", 
  breaks = c(-Inf, 0.0001, 1.5, 2, Inf), 
  labels = c("nada","pocos", "medio", "muchos")
)
warnings()
```

Reglas con muchos RT
```{r}
# generaciÃ³n de reglas: Aquellos con muchos RT
#trans <- as(top_tweets_by_retweet_count[c("cat_friends", "cat_favorite","cat_verified","cat_statuses","cat_followers", "cat_rt")], "transactions")
#rules = apriori(trans, parameter=list(target="rule", support=0.01, confidence=0.02), appearance = list(rhs = 'cat_rt=muchos'))
#print(rules)
#inspect(sort(rules, by="lift", decreasing = TRUE))
```

Reglas con muchos Favs
```{r}
# generaciÃ³n de reglas: Aquellos con muchos Favs
#trans <- as(top_tweets_by_retweet_count[c("cat_friends", "cat_favorite","cat_verified","cat_statuses","cat_followers", "cat_rt")], "transactions")
#rules = apriori(trans, parameter=list(target="rule", support=0.01, confidence=0.02), appearance = list(rhs = 'cat_favorite=muchos'))
#print(rules)
#inspect(sort(rules, by="lift", decreasing = TRUE))
```

Reglas de influencia del verified
4 Consigna, pregunta del TP pasado, independencia verified vs popularidad
```{r}
# generaciÃ³n de reglas 2- Influencia del verified
#trans <- as(top_tweets_by_retweet_count[c("cat_friends", "cat_favorite","cat_verified","cat_statuses","cat_followers", "cat_rt")], "transactions")
#rules = apriori(trans, parameter=list(target="rule", support=0.0001, confidence=0.02), appearance = list(lhs = 'cat_verified=si'))
#print(rules)
#inspect(sort(rules, by="lift", decreasing = TRUE))
```

Formato tuplas tweets-item (item equivale a la discretización de nuestra medición de retweets)
```{r}
# Pivot de columnas que empiezan con "cat"
df_tweets_tuples = top_tweets_by_retweet_count %>% 
  pivot_longer(
    cols = starts_with("cat"),
    names_to = "feat", 
    values_to = "val", 
    names_prefix = "cat_",
    values_drop_na = TRUE) %>% 
  select("status_id", "feat", "val")
```

Agregamos el prefijo del feature discretizado
```{r}
# se agrega prefijo de tipo de atributo-item
df_tweets_tuples = df_tweets_tuples %>% 
  mutate("item" = paste0(feat,"=",val)) %>% 
  select("status_id", "item")
```

```{r}
length(
  unique(df_tweets_tuples$status_id)
)
```

Hacemos un tratamiento de textos
```{r}
### ----- Tratamiento de Textos ------------
df_text = top_tweets_by_retweet_count[,c("status_id","text")]
```

Limpiamos caracteres no alfanumericos
```{r}
# Se quitan caracteres no alfanumÃ©ricos (por cuestiones de errores en RStudio)
df_text$text <- gsub("[^[:alnum:][:blank:]?&/\\-]", "", df_text$text)
df_text$text <- gsub("U00..", "", df_text$text)
```

Limpiamos los textos
```{r}
# Se quitan acentos
df_text$text = stri_trans_general(df_text$text, "Latin-ASCII")
# Se pasa a minusculas
df_text$text = tolower(df_text$text)
# Se quita puntuacion
df_text$text = removePunctuation(df_text$text)
# Se quitan nÃºmeros
df_text$text = removeNumbers(df_text$text)
# se quitan espacios extras
df_text$text =  stripWhitespace(df_text$text)
# se quitan espacios al principio y final de la cadena
df_text$text = str_trim(df_text$text)
# sin stop words
df_text$text = removeWords(df_text$text, stopwords("spanish"))
# sin stop words english
df_text$text = removeWords(df_text$text, stopwords("english"))
```

Tokenizamos el texto (separamos todos los terminos)
```{r}
# se separa el texto en terminos
df_text$words = tokenizers::tokenize_words(df_text$text, simplify = T)
```

Armamos tuplas usuario-termino (status_id,words)
```{r}
# se pasa a formato pares: tweet-words
df_text = df_text %>% select("status_id", "words")  %>% unnest(words) %>%  distinct()
```

Eliminamos terminos que no queremos
```{r}
# Elimino los términos de búsqueda de los hashtags
df_text = df_text[-grep(x = df_text$words, pattern = "^(covid|corona|coronavirus|cuarentena|virus|covid19|covid-19)"),]
```

Agregamos el prefijo de de tipo de atributo (word)
```{r}
# se agrega prefijo de tipo de Ã�tem:
df_text$item = paste0("word=", df_text$words)
```

Combinamos nuestros dataframes de tweets-RT junto con el de tweets-words
```{r}
# A las transacciones con hashtags se les agregan los atributos del usuario.
df_tuples = df_text[,c("status_id","item")]
df_tuples = bind_rows(
  df_tweets_tuples, 
  df_tuples
)
```

Generamos nuestras reglas
```{r}
# reglas
rt_words_transactions <- as(
  split(df_tuples$item, df_tuples$status_id), 
  "transactions"
)
print(rt_words_transactions)
```

```{r}
rules = apriori(
  rt_words_transactions,
  parameter = list(
    target="rule", 
    support=0.001, 
    confidence=0.02, 
    minlen=2
  ), 
  appearance = list(rhs = 'rt=muchos')
)
print(rules)
```

```{r}
View(
  inspect(
    sort(
      rules,
      by="lift", 
      decreasing = TRUE
    )[1:20]
  )
)
inspect(
  head(rules, 20)
)
```


```{r}
#Codigo Leo

# Buscar que el consecuente contenga items de tipo hashtag
# (%pin% indica matching parcial sobre el string del item)
inspect(
  subset(
    rules, 
    subset = lhs  
    %pin% "word=u"
  )
)

# Buscar que el antecedente contenga la word nex
inspect(
  subset(
    rules, 
    subset = lhs  %in% "word=new"
  )
)

# Buscar que el antecedente contenga la word urgente O abril
inspect(
  subset(
    rules, 
    subset = lhs  %in% c("word=urgente", "word=abril")
  )
)

# Buscar que el antecedente contenga la word casos Y confirmados
inspect(
  subset(
    rules, 
    subset = lhs  %ain% c("word=casos", "word=confirmados")
  )
)

# Buscar que el antecedente contenga alguna word y en el consecuente
# la cantidad de rt discretizada
inspect(
  subset(
    rules, 
    subset = lhs  %pin% "word=" & rhs  %pin% "rt="
  )
)

# Buscar que el antecedente contenga alguna word O
# en el consecuente la cantidad de rt discretizada
inspect(
  subset(
    rules, 
    subset = lhs  %pin% "word=" | rhs  %pin% "rt="
  )
)

# Buscar que el antecedente contenga alguna word y que 
# el antecedente NO contenga la word new
inspect(
  subset(
    rules, 
    subset = lhs  %pin% "word=" & !(lhs  %in% "word=new")
  )
)

# Buscar que el itemset (antecedente o consecuente) tenga una word
inspect(
  subset(
    rules, 
    subset = items  %pin% "word="
  )
)

# Buscar que el itemset (antecedente o concecuente) tenga una word Y que el lift sea mayor a 1.2
inspect(
  subset(
    rules, 
    subset = items  %pin% "word=" & lift > 1.2
  )
)
```
```{r}

apriori(
  train, 
  parameter = list(
    support=0.01, 
    confidence=0.1,
    target = "rules", 
    minlen=3, 
    maxlen=10
  )
)
```


